{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Initialise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from fastai.vision import *         # script requires fastai version 1.0.61\n",
    "from fastai.callbacks import *\n",
    "from image_tabular.core import *\n",
    "from image_tabular.metric import *\n",
    "\n",
    "from src.cnn_functions import SplitData\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warning\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='torch.nn.functional')\n",
    "\n",
    "# change device to use GPU if avalible\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for data location\n",
    "data_path = '../Cardiomegaly Classification/MIMIC_features/MIMIC_features.pkl'\n",
    "\n",
    "# Path for image location\n",
    "image_path = '../MIMIC/'\n",
    "\n",
    "# Path for model storage\n",
    "model_folder = '../Cardiomegaly Classification/models/cnn'\n",
    "model_storage = 'Image_CNN.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "DataSplits = [0.8, 0.1, 0.1]        # Spits of data for train, validation, and test sets\n",
    "norm_pixel = ([0.4712,],[0.3030,])  # Data normalisation: normalised pixel values in image\n",
    "size = 244                          # Data normalisation: normalised image size\n",
    "max_rot = 10                        # Data augmentaiton: maximum rotation\n",
    "Vflip = True                        # Data augmentation: vertical flips (True/False)   \n",
    "Hflip = True                        # Data augmentation: horizontal flips (Ture/False)\n",
    "\n",
    "# CNN parameters\n",
    "bs = 64                             # batch size\n",
    "epochs = 15                         # epochs of training\n",
    "lr = 1e-2                           # learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read \n",
    "data = pd.read_pickle(data_path)\n",
    "\n",
    "# Change name of column to indicate class deoaration\n",
    "data.rename(columns={'Cardiomegaly':'class'}, inplace=True)\n",
    "\n",
    "# Split into 5 folds\n",
    "[train_df, val_df, test_df] = SplitData(data, DataSplits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into dataframes for integration into fastai learner\n",
    "train_val_df = pd.concat([train_df,val_df]).reset_index(drop=True)\n",
    "train_test_df = pd.concat([train_df,test_df]).reset_index(drop=True)\n",
    "\n",
    "val_idx = val_df.index.to_numpy() + len(train_df)\n",
    "test_idx = test_df.index.to_numpy() + len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms applied on images for data augmentation\n",
    "tfms = get_transforms(max_rotate = max_rot, do_flip=Hflip, flip_vert=Vflip)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image data using train_df and prepare fastai LabelLists\n",
    "train_image_data = (ImageList.from_df(train_val_df, path=image_path, cols='path')\n",
    "                        .split_by_idx(val_idx)\n",
    "                        .label_from_df(cols='class')\n",
    "                        .transform(tfms, size=size)\n",
    "                        .databunch(bs=bs)\n",
    "                        .normalize(norm_pixel))\n",
    "\n",
    "# same for test data (but without transforms)\n",
    "test_image_data = (ImageList.from_df(train_test_df, path=image_path, cols='path')\n",
    "                            .split_by_idx(test_idx)\n",
    "                            .label_from_df(cols='class')\n",
    "                            .transform(size=size)\n",
    "                            .databunch(bs=bs)\n",
    "                            .normalize(norm_pixel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust loss function weight because the dataset is extremely unbalanced\n",
    "weights = [1/(1-train_df['class'].mean()), 1/train_df['class'].mean()]\n",
    "\n",
    "loss_func = CrossEntropyFlat(weight=torch.FloatTensor(weights).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package everything in fastai learner, use accuracy and auc roc score as metrics\n",
    "learn = cnn_learner(train_image_data, \n",
    "                    models.resnet50, \n",
    "                    lin_ftrs=[512, 256, 32], \n",
    "                    ps=0.2, \n",
    "                    metrics=[accuracy, ROCAUC()], \n",
    "                    loss_func=loss_func,\n",
    "                    path = model_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate figure to check if learning rate is appropriate\n",
    "learn.lr_find()\n",
    "x_unfrozenplot = learn.recorder.plot(return_fig=True)\n",
    "x_unfrozenplot.savefig(model_folder + 'learning_rate_fig.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and save version with lowest validation loss\n",
    "learn.fit_one_cycle(epochs, lr, callbacks=[SaveModelCallback(learn, monitor='valid_loss', mode='min')])\n",
    "learn.export(model_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data avaliable to model \n",
    "learn.data = test_image_data\n",
    "\n",
    "# Get predictions and make binary\n",
    "learn.validate()\n",
    "preds, targets = learn.get_preds()\n",
    "class_preds = np.argmax(preds, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "Accuracy = accuracy_score(targets, class_preds) \n",
    "print('Accuracy = ' + str(Accuracy))\n",
    "\n",
    "#F1 Score\n",
    "f1Score = f1_score(targets, class_preds)\n",
    "print('F1 Score = ' + str(f1Score))\n",
    "\n",
    "#Confusion Matrix\n",
    "CF = confusion_matrix(targets, class_preds)\n",
    "print(CF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1cba19b971ff694059e83efcf642bf4bc6078f5ed50d16de55abdc3eb9fc494"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
